{% extends "blog_frame.html" %}
{% block scripts %}
<link href="/static/css/prism.css" rel="stylesheet" />
<script src="/static/js/prism.js"></script>
{% endblock %}
{% block content %}

<img src="/static/post_assets/nyc-open-data-portal/nyc-open-data-banner.png" class="inline_image_full" alt="Data."/>

<h3>Introduction</h3>

<p>
    One of the most compelling trends in technology today is the open data and open governance
    movement. It's not without reason that no less than Tim Berners-Lee himself, the creator of the worldwide web
    and one of the most preeminent scholars of the Internet, is doing his latest work in getting more government
    data on the web:  <a
        href="http://bits.blogs.nytimes.com/2009/10/12/the-webs-inventor-regrets-one-small-thing/?_r=0">
    in an interview with <i>The New York Times</i></a> a few years ago he spoke to how even records as mundane as
    traffic statistics or weather data could drive tinkerers to "make government run better".
</p>

<p>
    New York City has been at the forefront of this movement: mayor Bloomberg (you know, the guy that founded
    <a href="http://www.bloomberg.com/">the largest multinational information broker in the world</a>) formalized
    a citywide analytics team as the <a
        href="http://www.governing.com/blogs/bfc/gov-new-york-city-data-driven-governance.html">Mayor's Office
        for Data Analytics</a> in 2013, and the effort has continued under Mayor De Blasio, with the city cementing
    its first <a href="http://www1.nyc.gov/site/analytics/index.page">Open Data Plan</a> in July 2015. The
    resultant <a href="https://nycopendata.socrata.com/">NYC Open Data Portal</a> was populated with over 1300
    datasets <a href="http://www.residentmar.io/2016/03/19/nyc-motor-vehicle-collisions.html">when I
    wrote this blurb for a post five months ago</a>&mdash;the count has jumped to 1500 now. It was, and is, the
    largest citywide open data portal in the world.
</p>

<p>
    Nevertheless, <a href="https://datasf.org/blog/how-to-measure-open-data/">a good open data platform is more than
    a count</a>; it's a function also of all of the maintenance and structure that goes into it. So I became curious:
    what does 1500 <i>mean</i>, exactly? What's a "dataset", who's publishing them, and how well-maintained are they?
</p>

<p>
    This post is about what I found.
</p>

<h3>Defining "dataset"</h3>

<img src="/static/post_assets/nyc-open-data-portal/nyc-open-data-dataset.png" class="inline_image_full" alt="Data."/>


<p>
    The New York City open data portal software is developed and maintained by <a href="https://socrata.com/">Socrata</a>,
    a late stage start-up with a dominant share of the (albeit increasingly competitive) US open data portal
    market. Socrata instances power the open data portal in New York City as well as ones in <a
        href="https://socrata.com/">Chicago</a>, <a href="https://data.sfgov.org/">San Francisco</a>, <a
        href="https://data.nola.gov/">New Orleans</a>, <a href="https://data.cityofboston.gov/">Boston</a>, <a
        href="https://opendata.lasvegasnevada.gov/">Las Vegas</a>, <a href="https://www.dallasopendata.com/">Dallas</a>
    ...the list goes on.
</p>

<!--<img src="/static/post_assets/nyc-open-data-portal/socrata-logo.png" class="inline_image"-->
     <!--alt="Data."/>-->

<p>
    Resources on a Socrata portal are organized as endpoints, each of which is given a unique URL. <b>As of writing,
    there are 8145 endpoints on the New York City Open Data Portal.</b>
</p>

<p>
    But Socrata endpoints can be all sorts of things: dataset-derived charts get endpoints, for example, as do
    filtered versions of datasets, multipane data visualizations Socrata refers to as "data stories", private or
    unpublished data uploaded by individual users, and so on.
</p>

<p>
    Thus studying data on an open data portal first requires nailing down a definition for the word "dataset" in the
    first place. Sadly there is no agreed on terminology for this, and different counts obtained in different ways
    will given you different results, even within the interface of the portal itself. Constructing a definition
    turned out to be a very non-trivial task; for the technically inclined, a <a href="https://github.com/ResidentMario/socrata-portal-metadata/blob/master/notebooks/Socrata%20Portal%20Dataset%20Counting%20Scoping.ipynb">Jupyter notebook</a> I wrote on
    the subject is an excellent primer on the matter.
</p>

<p>
    Here is the segmentation of published dataset endpoints I ultimately arrived at (all counts as of early August
    2016):
</p>
<ul>
    <li>
        <i>Tables</i> &mdash; This is the familiar spreadsheet-layout data format we all know and love. We have
        1073 of these.
    </li>
    <li>
        <i>Geospatial Datasets</i> &mdash; These are geographic datasets provided in <code class="inline_code">KML</code>,
        <code class="inline_code">KMZ</code>, <code class="inline_code">SHP</code>, or <code
            class="inline_code">GeoJSON</code> formats. There are 192 of these.
    </li>
    <li>
        <i>External Datasets</i> &mdash; These are public datasets provided elsewhere on the Internet and linked to
        from the portal. There are 174 of these.
    </li>
    <li>
        <i>Files/Blobs</i> &mdash; These are datasets uploaded to the open data portal in a non-geospatial zipped
        format. There are 92 of these.
    </li>
</ul>

<p>
    Adding these up, we find that <b>there are 1531 datasets on the New York City open data portal</b>&mdash;just
    like the banner advertises!
</p>

<h3>Characterizing New York City open data</h3>

<p>
    Let's start by looking at datasets by category:
</p>

<img src="/static/post_assets/nyc-open-data-portal/datasets-by-category.png" class="inline_image_full" alt="Data."/>

<p>
    This selection isn't actually particularly informative: on an open data portal for city government,
    everything is...city government...so the leading label is pretty meaningless. Still, it's interesting to see that
    education has a strong presence on the portal.
</p>

<p>
    Next up, here's dataset counts by ownership:
</p>

<img src="/static/post_assets/nyc-open-data-portal/datasets-by-ownership.png" class="inline_image_full" alt="Data."/>

<p>
    Again the DOE's education datasets put it in the lead, at least in terms of raw volume.
</p>

<p>
   How frequently are datasets updated?
</p>

<img src="/static/post_assets/nyc-open-data-portal/datasets-by-update-frequency.png" class="inline_image_full" alt="Data."/>

<p>
    Over a third of datasets are updated "as needed" (which really could mean anything between a few months and
    almost never); a significant further chunk of them claim annual update frequency. The fastest turnaround time
    achieved by the open data portal is daily frequency&mdash;the one "dataset" claiming minutely updates is actually
    the programmatically-generated Socrata master catalog, which is a thing that exists but isn't really what we're
    interested in.
</p>

<p>
    The logical next question is one of automation. While some datasets require manual administrating by the
    Department of Information Technology and Telecommunications, a slice of them (including, not inconsequentially,
    most of the more heavily utilized datasets) are updated by automatic tooling. Socrata data includes information
    on this...
</p>

<img src="/static/post_assets/nyc-open-data-portal/datasets-by-automation-type.png" class="inline_image_full" alt="Data."/>

<p>
    ...but unfortunately it is very incomplete. Most likely "NaN" corresponds with "No", which means that, in total,
    there are approximately 150 automatically updated open datasets. But it's hard to know for sure, at least
    independently.
</p>

<p>
    Next let's look at when these datasets were actually uploaded. What has the history of the growth of the open
    data portal been like?
</p>

<img src="/static/post_assets/nyc-open-data-portal/datasets-by-upload-date.png" class="inline_image_full" alt="Data."/>

<p>
    This plot shows that, in the early days, the New York City open data portal experienced <i>really</i> strong
    spikes in uploads. For whatever reason, in 2011 and 2013 the task of uploading new datasets was aggregated into
    sprints peaking out at specific days. The two most active upload dates of all time are 2011-09-29, which saw 65
    uploads, and 2013-02-21, which saw 53 of them. As the platform matures and evolves, the folks handling these
    uploads have smoothed them out over the course of the year, making this hail mary a thing of the
    past&mdash;<i>mostly</i>.
</p>

<p>
    I suggest that, when it comes to data timeliness, it's more meaningful to look at update <i>recency</i> than it
    is at the promises thereof in the datasets' metadata. With that in mind, here is a cumulative plot of the data
    update recency of all of the datasets on the open data portal, going back two years to August 2014:
</p>

<img src="/static/post_assets/nyc-open-data-portal/datasets-by-recency-cumulative.png" class="inline_image_full" alt="Data."/>

<p>
    About 100 datasets have been updated in the last two months (~7% of the ~1500 total), about 400 in the last six
    months (~25%), about 450 within the last year (~30%), and about 650 within the last two years (~45%).
    Unfortunately it's not possible to go any further back because a software update at that time seems to have
    touched the <code class="inline_code">updatedAt</code> parameter of every dataset on the portal.
</p>

<p>
    One last parameter I looked at was dataset popularity. Not unexpectedly (per <a
        href="https://en.wikipedia.org/wiki/Zipf%27s_law">Zipf's law</a>) this turned out to follow a logarithmic
    distribution. For instance, the top ten datasets on the open data portal had <code class="inline_code">[167921,
   18697, 13908, 12959, 11463, 5866, 3038, 2897, 2497, 2406]</code> views, necessitating that the following plot
    squeeze on a logarithmic axis, where each tick represents a tenfold increase in view-count:
</p>

<img src="/static/post_assets/nyc-open-data-portal/datasets-by-page-views.png" class="inline_image_full" alt="Data."/>

<p>
    You know what? <a href="https://nycopendata.socrata.com/analytics">Socrata does this one better</a>.
</p>

<h3>Running your own analysis</h3>

<p>
    The techniques I used to get the data I used for this study are mostly transparent and totally transferable to
    any Socrata portal of interest.
</p>

<p>
    Socrata portals provide metadata about their data in two different formats: the <a
        href="http://labs.socrata.com/docs/search.html">Socrata Catalog API</a>, which provides rich metadata on
    every endpoint on a portal, and the <code class="inline_code"><a href="https://data.cityofnewyork.us/data.json">
    data.json</a></code> endpoint, which provides only endpoints fitting our definition of a "dataset", but has less
    information on them. Thus to get the most out of portal metadata we have to match the endpoints returned by <code
        class="inline_code">data.json</code> to the ones returned by the catalog API.
</p>

<p>
    I've made the resources I've used for this project&mdash;including the code handling that match&mdash;available on
    my <code class="inline_code"><a href="https://github.com/ResidentMario/socrata-portal-metadata">socrata-portal-metadata</a></code>
    repository on GitHub. If you want to replicate this study for your own home portal, that is where you should go!
</p>

<p class="addendum">
    Want to see more longitudinal data on open data portals nationwide? Then Thomas Levine's <a
        href="https://thomaslevine.com/!/socrata-summary/">"Analyzing all the datasets"</a> has got you covered.
</p>

{% endblock %}